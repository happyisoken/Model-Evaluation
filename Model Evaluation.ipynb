{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc02066-2f8f-4926-bda2-a2c73b8a9a50",
   "metadata": {},
   "source": [
    "### Model Evaluation and Refinement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a44fd6-c45e-4635-8e5e-ec6a4ee4d567",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "This tells us how well a model performs in the real world\n",
    "\n",
    "In-sample evaluation tells us how well our model will fit the data used to train it.\n",
    "\n",
    "Problem: It does not tell us how well the trined model can be used to predict new data.\n",
    "\n",
    "Solution: \n",
    "- Split the data up using the In_sample data or training data to train the model\n",
    "- The rest of the data called test data is used as Out-of-sample evaluation or test set.\n",
    "\n",
    "\n",
    "#### Training/Testing Sets\n",
    "Test data gives an idea how our data will perform.\n",
    "\n",
    "- When we split, the larger part of the data is used for triaing while the rest is used for testing E.g training set 70%, while testing is 30%\n",
    "- Build and train the model with a training set\n",
    "- Use training set to assess the performance of the predictive model\n",
    "- When we have completed testing our model, we should use all the data to train the model to get the best performance.\n",
    "\n",
    "Function train_test_split() - Split data into random train and test subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a0a5f-11ff-4d25-a7d0-0eb137bfe5e3",
   "metadata": {},
   "source": [
    "### Generalization Performance\n",
    "\n",
    "- Generalization error is a measure of how well our data does at predicting previously unseen data\n",
    "- The error obtained using our testing data is an approximation of this error.\n",
    "\n",
    "Lots of Training Data\n",
    "\n",
    "Using a lot of data for training gives an accurate means of determining how well our model will perform in the real world but the precision of performance will be lo and vice versa\n",
    "\n",
    "To overcome this problem, we use the Cross Validation method\n",
    "Cross Validation:\n",
    "- Most common out-of-sample evaluation metrics\n",
    "- More effective use oof data (each observation is used for both training and testing\n",
    "\n",
    "Function cross_val_score()\n",
    " - returns the prediction that was obtained for each element when it was in the test set\n",
    " - Has a similar interface to cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2addc485-f7b4-4364-b635-345414ba20d2",
   "metadata": {},
   "source": [
    "### Overfitting, Underfitting and Model Selection \n",
    "\n",
    "Overfitting: Model is too fexible to fix the noise rather than the function\n",
    "\n",
    "Underfitting: Model is too simple to fit the data\n",
    "\n",
    "Model Selection: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869f150-df4c-4a4b-9565-943879283d83",
   "metadata": {},
   "source": [
    "### Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73faf4-f0b8-4517-8a31-749668c34cee",
   "metadata": {},
   "source": [
    "Evaluation metric: A way to quantify performance of a machine learning model.\n",
    "Evaluation metric ins not same as Loss function\n",
    "\n",
    "#### Classification Metrics\n",
    "\n",
    "Binary classification\n",
    "\n",
    "Classification accuracy: Accuracy = Number of correct predictions/Total number of predictions\n",
    "\n",
    "Dummy classifier doesnt learn anything from the data\n",
    "\n",
    "#### Confusion matrix\n",
    "- Not a metric\n",
    "- Helps to gain insight into the type of errors a model is making\n",
    "- Helps to understand some other metrics\n",
    "\n",
    "Precision = TP/TP + FP where TP is True Positives an FP is False positives\n",
    "\n",
    "#### Matthews Correlation Coefficient\n",
    "\n",
    "Another way to sum up confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6221ad-c2c4-4c99-90b4-5b2010709609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
